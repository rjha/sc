
#my.cnf changes
-----------------

we make some changes to default my.cnf file. This is done to ensure that 

1) we are working with utf-8 (Also make sure to create DB etc. with default utf-8 charset.)
2) bind-address is right (private IP or 127.0.0.1)
   bind-address private IP would mean creating a local and remote user.
3) Tx isolation level for innodb. 
4) logging for slow queries. 


---------------x--------------------


[client]
default-character-set=utf8

[mysqld]
default-time-zone='+00:00'
default-character-set=utf8
collation-server = utf8_general_ci
init-connect='SET NAMES utf8'
character-set-server = utf8
skip-character-set-client-handshake

user        = mysql
socket      = /var/run/mysqld/mysqld.sock
port        = 3306
basedir     = /usr
datadir     = /var/lib/mysql
tmpdir      = /tmp
skip-external-locking
transaction-isolation=READ-COMMITTED

bind-address=<private IP>

log_slow_queries    = /var/log/mysql/mysql-slow.log
long_query_time = 2

[mysqldump]
default-character-set=utf8
quick
quote-names
max_allowed_packet  = 16M

[mysql]
default-character-set=utf8

------------------x----------------------



# create database
create database mydb  character set utf8 collate utf8_general_ci ;
grant all privileges on mydb.* to 'user'@'host' identified by 'password' with grant option ;

for private IP - create a user that can connect from 
    - localhost
    - this private IP
    - from another node private IP


#show triggers on a table, [show triggers] will show *all* triggers
show triggers LIKE '%block%'\G
show triggers LIKE '%trg_new_org_menu%'\G

#finding constraints on a table like UNIQUE constraints
select * from information_schema.table_constraints where table_schema =schema() and table_name  = 'gloo_ml_menu' ;

#Dropping a UNIQUE constraint
alter table gloo_ca_login drop index login ;

#Add a UNIQUE constraint with name
alter table  gloo_ca_login add constraint UNIQUE uniq_ca_login (org_id,login);

#show indexes on a table 
show index from news_post ;

#Add an index
alter table news_post add index media_index (s_media_id);

#dropping an index 
alter table news_post drop index [index_name]


#show all  procedures/triggers for current schema

select routine_name from information_schema.routines where routine_schema = schema() ;
select trigger_name from information_schema.triggers where trigger_schema = schema();

# Error 1172 
# At times you first want to create a schema and then load data into it (vs. a full dump)
Error 1172 can happen because the triggers are again fired on table and you try to again create data 
that is already part of the dump. It is advisable to use full dumps always.
Another solution is to load dump w/o enabling triggers. (remove triggers from your schema definition)
You need to run proc/triggers scripts as  MYSQL root.


# data-dump.sh

x=`date +%d%m%Y`
mysqldump  --no-create-info --complete-insert --skip-extended-insert
--skip-triggers -u root -p webgloo250710 > webgloodb.data.$x.sql


#full-dump.sh

x=`date +%d%m%Y`
mysqldump  --complete-insert --add-drop-table   --triggers  --routines
-u root -p webgloo250710 > webgloodb.full.$x.sql

#schema-dump.sh

x=`date +%d%m%Y`
mysqldump --no-data --add-drop-table --triggers --routines
-u root -p webgloo250710  > webgloodb.schema.$x.sql

# MYSQL JDBC UTF-8 char insert issue

The local windows mysql DB was created as UTF-8 DB. Now we loaded/created these tables using a
script dumped from server DB. server DB was installed with default charset (latin1)
That dump script had default charset for tables as latin1 like:

create table ...
) ENGINE=MyISAM AUTO_INCREMENT=14072 DEFAULT CHARSET=latin1;


=> This leads to some issues. when JDBC tries to insert UTF-8 strings into such table columns we get errors like
java.sql.SQLException: Incorrect string value: '\xD0\x9A\xD0\xB5\xD0\xB9...' for column 'widget_html' at row 1
        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1075)
        at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3566)
        at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3498)

The remedy is to fix the charset and collation for tables created using server DB dump.
You have to do this for all problematic tables.

mysql> alter table gloo_auto_post  convert to character set utf8 collate utf8_general_ci ;

One more related error (when altering tables to utf-8 is following:
mysql> alter table gloo_page  convert to character set utf8 collate utf8_general_ci ;
ERROR 1071 (42000): Specified key was too long; max key length is 1000 bytes

=> what this means is : earlier in latin1 our unique column was 512 char (byte) wide
Now when we switch to utf8 we need (512 char x3 bytes/char = 1536 bytes) and that exceeds mysql limit of
1000 bytes on keys. Solution is to change key lenght to be within 1000 /3 chars with utf8 charset.

mysql> alter table gloo_page modify column seo_key varchar(256);

#recommended
----------------------

key_buffer_size=64M
table_cache=256
sort_buffer_size=4M
read_buffer_size=1M
query_cache_limit=2M
query_cache_size=8M
max_connections=32
thread_cache_size=16


#calculate max_connections
-----------------------------------

mysql> show variables like '%BUFFER%';
+-------------------------+----------+
| Variable_name           | Value    |
+-------------------------+----------+
| bulk_insert_buffer_size | 8388608  |
| join_buffer_size        | 131072   |
| key_buffer_size         | 16777216 |
| myisam_sort_buffer_size | 8388608  |
| net_buffer_length       | 16384    |
| preload_buffer_size     | 32768    |
| read_buffer_size        | 131072   |
| read_rnd_buffer_size    | 262144   |
| sort_buffer_size        | 2097144  |
| sql_buffer_result       | OFF      |
+-------------------------+----------+
10 rows in set (0.00 sec)

mysql> show variables like 'thread_cache_size';

Global Buffer

key_buffer_size 16,777216
net_buffer_length 16384
myisam_sort_buffer_size 8,388608
bulk_insert_buffer_size 8,388608
query_cache_size  16777216
max_heap_table_size  16777216
tmp_table_size  16777216 



Thread Buffers
     
preload_buffer_size   32768
sort_buffer_size 2,097144  2M
read_buffer_size        0,131072 
join_buffer_size        0,131072 
read_rnd_buffer_size    0,262144


 
#internal temporary tables
--------------------------------
In some cases, the server creates internal temporary tables while processing queries.
This may be required for GROUP BY and DISTINCT etc. Now to see whether a SQL query will 
use internal temporary tables, use EXPLAIN PLAN

Q. when do we use in-memory temporary table and when do we use on disk temporary tables?
Tables with BLOB and TEXT columns will use on disk temporary tables.


#explain plan
-------------


+precede a select statement with explain [extended] keyword

mysql> explain extended select post.*, media.bucket, media.id as media_id, media.stored_name,media.original_name, media.original_height,media.original_width from news_post post LEFT  JOIN news_media media ON post.s_media_id = media.id order by post.created_on DESC;
+----+-------------+-------+--------+---------------+---------+---------+------------------------+------+----------+----------------+
| id | select_type | table | type   | possible_keys | key     | key_len | ref                    | rows | filtered | Extra          |
+----+-------------+-------+--------+---------------+---------+---------+------------------------+------+----------+----------------+
|  1 | SIMPLE      | post  | ALL    | NULL          | NULL    | NULL    | NULL                   |   11 |   100.00 | Using filesort |
|  1 | SIMPLE      | media | eq_ref | PRIMARY       | PRIMARY | 4       | newsdb.post.s_media_id |    1 |   100.00 |                |
+----+-------------+-------+--------+---------------+---------+---------+------------------------+------+----------+----------------+
2 rows in set, 1 warning (0.00 sec)


Here we are doing a FTS (Full Table Scan) on news_post table when using LIMIT on created_on variable


mysql> explain select * from news_post order by created_on desc LIMIT 1,5 ;
+----+-------------+-----------+------+---------------+------+---------+------+------+----------------+
| id | select_type | table     | type | possible_keys | key  | key_len | ref  | rows | Extra          |
+----+-------------+-----------+------+---------------+------+---------+------+------+----------------+
|  1 | SIMPLE      | news_post | ALL  | NULL          | NULL | NULL    | NULL |   11 | Using filesort |
+----+-------------+-----------+------+---------------+------+---------+------+------+----------------+
1 row in set (0.00 sec)

If we create an index on created_on then the plan would use that index

mysql/> alter table news_post add index co_index(created_on);

mysql> explain extended select post.*, media.bucket, media.id as media_id,
    ->  media.stored_name,media.original_name, media.original_height,media.original_width
    ->  from news_post post LEFT  JOIN news_media media ON post.s_media_id = media.id 
    ->  order by post.created_on DESC LIMIT 0,10;
+----+-------------+-------+--------+---------------+----------+---------+------------------------+------+----------+-------+
| id | select_type | table | type   | possible_keys | key      | key_len | ref                    | rows | filtered | Extra |
+----+-------------+-------+--------+---------------+----------+---------+------------------------+------+----------+-------+
|  1 | SIMPLE      | post  | index  | NULL          | co_index | 4       | NULL                   |   10 | 11190.00 |       |
|  1 | SIMPLE      | media | eq_ref | PRIMARY       | PRIMARY  | 4       | newsdb.post.s_media_id |    1 |   100.00 |       |
+----+-------------+-------+--------+---------------+----------+---------+------------------------+------+----------+-------+
2 rows in set, 1 warning (0.00 sec)




#slow queries log
------------------

on Ubuntu machines, go to /etc/mysql/my.cnf file and turn on following 2 options under [mysqld] section
(Query not using indexes - Better use explain plan ..)

log_slow_queries        = /var/log/mysql/mysql-slow.log
long_query_time = 2
#log-queries-not-using-indexes

restart the server and slow query logs will be in /var/log/mysql folder.
Copy those files to your home area and examine with mysqldumpslow, like

rjha@indigloo-beta:~/mysql$ sudo cp /var/log/mysql/mysql-slow.log.5.gz .
rjha@indigloo-beta:~/mysql$ sudo chown -R rjha:rjha mysql*
rjha@indigloo-beta:~/mysql$ gunzip *.gz
rjha@indigloo-beta:~/mysql$ mysqldumpslow *.* | less



#Maosx pre-packaged MySQL
--------------------------

Macosx bundled mysql is installed in /usr/local/mysql
Macosx install uses mysql defaults and there is no my.cnf as such
To get a copy of my.cnf do :-

rjha @mbp /usr/local/mysql $ sudo cp support-files/my-small.cnf  /etc/my.cnf
Then edit my.cnf in usual way and restart the mysqld daemon
we have checked in macosx my.cnf in misc/ folder (there are some changes)
1) on macosx innodb support is built-in (for whatever reason) so we cannot put skip-innodb in my.cnf
2) leave datadir etc as default (donot put in .cnf file)
3) change socket location - on macosx it is in /tmp/mysql.sock (and not mysqld)
4) use slow_query_log (needs > 5.1.12, on macosx lion, we have 5.5.15

@mbp ~ $ mysql --version
mysql  Ver 14.14 Distrib 5.5.15, for osx10.6 (i386) using readline 5.1


# how to see mysql connection ID (for questions like who is holding Tx etc.) 
------------------------------------
The connection_id is kept in general query log
Also, we can log them to a DB table if we so wish

DROP TABLE IF EXISTS mysql_connections ;
CREATE TABLE mysql_connections (
    id INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY, 
    connect_time DATETIME NOT NULL, 
    user_host VARCHAR(32) NOT NULL, 
    connection_id INT UNSIGNED NOT NULL 
) ENGINE = InnoDB default character set utf8 collate utf8_general_ci;

put this at top of [mysqld] section in /etc/mysql/my.cnf file
init_connect will be fired for every connection

@see http://dev.mysql.com/doc/refman/5.0/en/server-system-variables.html#sysvar_init_connect 
init_connect = 'INSERT INTO scdb.mysql_connections (connect_time, user_host, connection_id) VALUES (NOW(), CURRENT_USER(), CONNECTION_ID()) '

The init_connect will not fire for users with SUPER privileges , that is of little consequence to us
since our web app runs as a different user. To check super privileges => see mysql.user table - user and 
super_priv columns



#PDO exceptions by default
---------------------------
PDO will not throw exceptions by default, you have to turn on the right PDO ATTRiBUTES 




